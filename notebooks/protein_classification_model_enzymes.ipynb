{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d69b13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfdefb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from constants import plots3d_path, persistence_path, landscapes_path\n",
    "from data_analysis_utils.utils import define_features_var_grouping\n",
    "from data_analysis_utils.proteins_similarity import pairwise_dist, aggregate_metrics_dim, aggregate_metrics_all, get_samples_low_high_pos_dist, compare_pdb_pairwise_dist\n",
    "from data_analysis_utils.visualization import apply_mds, compare_pdb_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d43c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_scripts.tda_encoding import get_encoded_proteins_from_coords\n",
    "from data_scripts.get_protein_data import download_pdb_from_id, extract_3dcoords_from_pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d07d2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_connected_proteins(df_tda_enc):\n",
    "    # Remove proteins we are not sure if connected by taking a look at persistence in dim 0\n",
    "    df_tda_enc['connected'] = np.where(((df_tda_enc.end_dim0_0 - df_tda_enc.end_dim0_1) > (df_tda_enc.end_dim0_1 - df_tda_enc.end_dim0_4)), 'Unknown', 'True')\n",
    "    return df_tda_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63b8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_approximated_land_area(df_tda_enc, dim, land, feat_var_dict_dim_land):\n",
    "    # Approximate area under land i for dimension 1 and 2\n",
    "    # Area without scaling on x axis is proportional to area with scaling * domain length - Attention, this is not true for landscapes with multiple peaks -e.g. not connected proteins for which the landscapes is 0 between the peaks!!\n",
    "    dim_land_shape_vars = [var for var in features_var_dict_dim_land[f'dim{dim}_land{land}'] if ('begin' not in var) and ('end' not in var)]\n",
    "    df_tda_enc[f'area_dim{dim}_land{land}'] = df_tda_enc[dim_land_shape_vars].apply(lambda x: np.linalg.norm(x),axis=1) * (df_tda_enc[f'end{land-1}_dim{dim}'] - df_tda_enc[f'begin{land-1}_dim{dim}'])\n",
    "    return df_tda_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60cfef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interesting_homology_filter(df_tfda_enc, feat_var_dict_dim_land):\n",
    "    # Infer if protein is connected from 0 dim homology\n",
    "    df = flag_connected_proteins(df_tfda_enc)\n",
    "    \n",
    "    # Get landscape areas: bigger the i-th area bigger the i-th hole\n",
    "    for dim in range(1,3):\n",
    "        for land in range(1,4): \n",
    "            df = get_approximated_land_area(df_tda_enc=df, dim=dim, land=land, feat_var_dict_dim_land=feat_var_dict_dim_land)\n",
    "\n",
    "    # Remove proteins that may not be connected\n",
    "    df = df[df['connected']=='True']\n",
    "    \n",
    "    # Remove proteins we are not sure if having interesting dim1 and dim2 homology by removing proteins those with small area under land1\n",
    "    df = df[(df['area_dim1_land1'] > np.percentile(df['area_dim1_land1'],95)) | (df['area_dim2_land1'] > np.percentile(df['area_dim2_land1'],95))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d1a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_protein_pairs(df_tda_enc, pair_dist, different_type_constraint=False, n=5):\n",
    "    # Get top pairwise distance\n",
    "    df_pair_dist_top = get_samples_low_high_pos_dist(pair_dist, n=n)\n",
    "    # Remove duplicates (distance is symmetric)\n",
    "    df_pair_dist_top_no_dup = df_pair_dist_top.loc[df_pair_dist_top[['pdb_id1','pdb_id2']].apply(set,axis=1).drop_duplicates().index].reset_index(drop=True)\n",
    "    # Filter to proteins having different types (it's more interesting)\n",
    "    df_pair_dist_top_no_dup = df_pair_dist_top_no_dup\\\n",
    "        .merge(df_tda_enc[['pdb_id', 'enzyme_type','area_dim1_land1','area_dim1_land2','area_dim1_land3','area_dim2_land1','area_dim2_land2','area_dim2_land3']], left_on='pdb_id1',right_on='pdb_id')\\\n",
    "        .rename(columns={'enzyme_type':'type_1','area_dim1_land1':'area_dim1_land1_pdb1','area_dim1_land2':'area_dim1_land2_pdb1','area_dim1_land3':'area_dim1_land3_pdb1','area_dim2_land1':'area_dim2_land1_pdb1','area_dim2_land2':'area_dim2_land2_pdb1','area_dim2_land3':'area_dim2_land3_pdb1'})\\\n",
    "        .drop(columns='pdb_id')\\\n",
    "        .merge(df_tda_enc[['pdb_id', 'enzyme_type','area_dim1_land1','area_dim1_land2','area_dim1_land3','area_dim2_land1','area_dim2_land2','area_dim2_land3']], left_on='pdb_id2',right_on='pdb_id')\\\n",
    "        .rename(columns={'enzyme_type':'type_2','area_dim1_land1':'area_dim1_land1_pdb2','area_dim1_land2':'area_dim1_land2_pdb2','area_dim1_land3':'area_dim1_land3_pdb2','area_dim2_land1':'area_dim2_land1_pdb2','area_dim2_land2':'area_dim2_land2_pdb2','area_dim2_land3':'area_dim2_land3_pdb2'})\\\n",
    "        .drop(columns='pdb_id')\n",
    "    if different_type_constraint:\n",
    "        df_similar_dist = df_pair_dist_top_no_dup[df_pair_dist_top_no_dup['type_1']!=df_pair_dist_top_no_dup['type_2']].sort_values(by='distance').reset_index(drop=True)\n",
    "    else:\n",
    "        df_similar_dist = df_similar_dist.sort_values(by='distance').reset_index(drop=True)\n",
    "    return df_similar_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35e3e7",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e38c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14183, 84)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load encoded data with enzyme type and pdb_id\n",
    "df_raw = pd.read_csv('output/tda_encoded_proteins_assembly.csv')\n",
    "df_raw = shuffle(df_raw, random_state=17).reset_index(drop=True)\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e75e0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_dim0_4</th>\n",
       "      <th>end_dim0_3</th>\n",
       "      <th>end_dim0_2</th>\n",
       "      <th>end_dim0_1</th>\n",
       "      <th>end_dim0_0</th>\n",
       "      <th>begin0_dim1</th>\n",
       "      <th>end0_dim1</th>\n",
       "      <th>a00_dim1</th>\n",
       "      <th>a10_dim1</th>\n",
       "      <th>b10_dim1</th>\n",
       "      <th>...</th>\n",
       "      <th>b12_dim2</th>\n",
       "      <th>a22_dim2</th>\n",
       "      <th>b22_dim2</th>\n",
       "      <th>a32_dim2</th>\n",
       "      <th>b32_dim2</th>\n",
       "      <th>a42_dim2</th>\n",
       "      <th>b42_dim2</th>\n",
       "      <th>a52_dim2</th>\n",
       "      <th>b52_dim2</th>\n",
       "      <th>pdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>0.031053</td>\n",
       "      <td>0.031109</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.033875</td>\n",
       "      <td>0.038172</td>\n",
       "      <td>0.041647</td>\n",
       "      <td>0.809293</td>\n",
       "      <td>0.576306</td>\n",
       "      <td>-0.231065</td>\n",
       "      <td>-0.008005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>-0.003667</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>3WWQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>0.037253</td>\n",
       "      <td>0.041352</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>0.049673</td>\n",
       "      <td>0.055790</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.734540</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>0.022359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>-0.010462</td>\n",
       "      <td>-0.004101</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>6FJF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9128</th>\n",
       "      <td>0.012660</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>0.013939</td>\n",
       "      <td>0.014772</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.431716</td>\n",
       "      <td>0.052027</td>\n",
       "      <td>0.008269</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>-0.000313</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>1KTL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>0.016735</td>\n",
       "      <td>0.016945</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.020255</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>1.079295</td>\n",
       "      <td>0.252217</td>\n",
       "      <td>0.070922</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>-0.007181</td>\n",
       "      <td>-0.009053</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>-0.000719</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>7TN9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10632</th>\n",
       "      <td>0.016606</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>0.017511</td>\n",
       "      <td>0.018205</td>\n",
       "      <td>0.141734</td>\n",
       "      <td>4.260686</td>\n",
       "      <td>3.138791</td>\n",
       "      <td>-1.243535</td>\n",
       "      <td>-0.008632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118243</td>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.016348</td>\n",
       "      <td>-0.038156</td>\n",
       "      <td>-0.019759</td>\n",
       "      <td>0.031078</td>\n",
       "      <td>0.022973</td>\n",
       "      <td>-0.001198</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>7WZ3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       end_dim0_4  end_dim0_3  end_dim0_2  end_dim0_1  end_dim0_0  \\\n",
       "6263     0.031053    0.031109    0.031736    0.033875    0.038172   \n",
       "2484     0.037253    0.041352    0.043844    0.049673    0.055790   \n",
       "9128     0.012660    0.013713    0.013939    0.014772    0.016293   \n",
       "8878     0.016735    0.016945    0.018145    0.020255    0.021961   \n",
       "10632    0.016606    0.016822    0.017014    0.017511    0.018205   \n",
       "\n",
       "       begin0_dim1  end0_dim1  a00_dim1  a10_dim1  b10_dim1  ...  b12_dim2  \\\n",
       "6263      0.041647   0.809293  0.576306 -0.231065 -0.008005  ... -0.001668   \n",
       "2484      0.005469   0.734540  0.032304  0.014172  0.022359  ...  0.011251   \n",
       "9128      0.009876   0.431716  0.052027  0.008269  0.041952  ...  0.002368   \n",
       "8878      0.032096   1.079295  0.252217  0.070922  0.011673  ...  0.017554   \n",
       "10632     0.141734   4.260686  3.138791 -1.243535 -0.008632  ... -0.118243   \n",
       "\n",
       "       a22_dim2  b22_dim2  a32_dim2  b32_dim2  a42_dim2  b42_dim2  a52_dim2  \\\n",
       "6263   0.007618  0.003524 -0.001965 -0.003667  0.000198  0.001975  0.000456   \n",
       "2484  -0.010462 -0.004101 -0.000637 -0.000441  0.001366  0.001842  0.000345   \n",
       "9128   0.000154 -0.005473 -0.002060  0.001841 -0.000313  0.000148 -0.000083   \n",
       "8878  -0.007181 -0.009053 -0.001113 -0.002425 -0.000719  0.001023  0.001347   \n",
       "10632  0.049629  0.016348 -0.038156 -0.019759  0.031078  0.022973 -0.001198   \n",
       "\n",
       "       b52_dim2  pdb_id  \n",
       "6263  -0.000788    3WWQ  \n",
       "2484  -0.000658    6FJF  \n",
       "9128   0.000581    1KTL  \n",
       "8878   0.001480    7TN9  \n",
       "10632 -0.001228    7WZ3  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(df_raw, random_state=17).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13d6801b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_dim0_4</th>\n",
       "      <th>end_dim0_3</th>\n",
       "      <th>end_dim0_2</th>\n",
       "      <th>end_dim0_1</th>\n",
       "      <th>end_dim0_0</th>\n",
       "      <th>begin0_dim1</th>\n",
       "      <th>end0_dim1</th>\n",
       "      <th>a00_dim1</th>\n",
       "      <th>a10_dim1</th>\n",
       "      <th>b10_dim1</th>\n",
       "      <th>...</th>\n",
       "      <th>b12_dim2</th>\n",
       "      <th>a22_dim2</th>\n",
       "      <th>b22_dim2</th>\n",
       "      <th>a32_dim2</th>\n",
       "      <th>b32_dim2</th>\n",
       "      <th>a42_dim2</th>\n",
       "      <th>b42_dim2</th>\n",
       "      <th>a52_dim2</th>\n",
       "      <th>b52_dim2</th>\n",
       "      <th>pdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016653</td>\n",
       "      <td>0.016829</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>0.008818</td>\n",
       "      <td>2.287163</td>\n",
       "      <td>0.397747</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.212187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001136</td>\n",
       "      <td>-0.015003</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>0.013206</td>\n",
       "      <td>-0.006437</td>\n",
       "      <td>-0.023021</td>\n",
       "      <td>-0.014598</td>\n",
       "      <td>-0.011707</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>5N60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.322974</td>\n",
       "      <td>0.116917</td>\n",
       "      <td>-0.042125</td>\n",
       "      <td>0.051454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003463</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>-0.012425</td>\n",
       "      <td>-0.003859</td>\n",
       "      <td>0.003016</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.001436</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>1OED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028250</td>\n",
       "      <td>0.028999</td>\n",
       "      <td>0.029191</td>\n",
       "      <td>0.029231</td>\n",
       "      <td>0.033350</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>0.924789</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>0.006648</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.006174</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>4AC7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017916</td>\n",
       "      <td>0.018095</td>\n",
       "      <td>0.018544</td>\n",
       "      <td>0.018621</td>\n",
       "      <td>0.991182</td>\n",
       "      <td>0.514619</td>\n",
       "      <td>3.548179</td>\n",
       "      <td>1.570846</td>\n",
       "      <td>-0.679233</td>\n",
       "      <td>-0.455567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.020321</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>0.014369</td>\n",
       "      <td>-0.002203</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.011260</td>\n",
       "      <td>-0.001214</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>6QV0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.043156</td>\n",
       "      <td>0.055253</td>\n",
       "      <td>0.056881</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.138809</td>\n",
       "      <td>0.068090</td>\n",
       "      <td>2.583287</td>\n",
       "      <td>0.718226</td>\n",
       "      <td>-0.116782</td>\n",
       "      <td>0.383141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>-0.000466</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>-0.001430</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>4UJ3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   end_dim0_4  end_dim0_3  end_dim0_2  end_dim0_1  end_dim0_0  begin0_dim1  \\\n",
       "0    0.016653    0.016829    0.017497    0.018127    0.020563     0.008818   \n",
       "1    0.013948    0.018293    0.018507    0.019814    0.020948     0.015655   \n",
       "2    0.028250    0.028999    0.029191    0.029231    0.033350     0.005733   \n",
       "3    0.017916    0.018095    0.018544    0.018621    0.991182     0.514619   \n",
       "4    0.043156    0.055253    0.056881    0.101645    0.138809     0.068090   \n",
       "\n",
       "   end0_dim1  a00_dim1  a10_dim1  b10_dim1  ...  b12_dim2  a22_dim2  b22_dim2  \\\n",
       "0   2.287163  0.397747  0.008854  0.212187  ... -0.001136 -0.015003  0.015701   \n",
       "1   0.322974  0.116917 -0.042125  0.051454  ... -0.003463 -0.003617 -0.012425   \n",
       "2   0.924789  0.010331  0.006648  0.005211  ...  0.007018 -0.000143 -0.006174   \n",
       "3   3.548179  1.570846 -0.679233 -0.455567  ... -0.000155 -0.020321  0.010022   \n",
       "4   2.583287  0.718226 -0.116782  0.383141  ...  0.001824  0.002775  0.002837   \n",
       "\n",
       "   a32_dim2  b32_dim2  a42_dim2  b42_dim2  a52_dim2  b52_dim2  pdb_id  \n",
       "0  0.013206 -0.006437 -0.023021 -0.014598 -0.011707  0.013695    5N60  \n",
       "1 -0.003859  0.003016  0.001733 -0.000613 -0.001436 -0.000055    1OED  \n",
       "2  0.001364  0.001377 -0.002091 -0.000105  0.001839  0.001000    4AC7  \n",
       "3  0.014369 -0.002203 -0.001113 -0.011260 -0.001214  0.006310    6QV0  \n",
       "4  0.001003  0.003037 -0.000466  0.002592 -0.001430  0.002117    4UJ3  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f09c5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85527, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load table with uniprot id, pdb id and Enzyme Classification number\n",
    "df_pue = pd.read_csv('data/pdb_uniprot_ec.csv')\n",
    "df_pue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add uniprot id and EC number info to encoded data \n",
    "df_puet = df_raw.merge(df_pue)\n",
    "df_puet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f660d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to enzymes having EC number (it seems a lot do not have it recorded in pdb file) and uniprot id (few don't have)\n",
    "df_with_ec = df_puet.dropna().reset_index(drop=True)\n",
    "print(df_with_ec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793c0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In very few cases EC number doesn't correspond with enzyme type. Let's filter out those samples\n",
    "df = df_with_ec[df_with_ec['enzyme_type'].apply(lambda x: str(enzyme_ec_label_dict[x])) == df_with_ec['ec_num'].apply(lambda x: x[0])]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68cd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC number distribution\n",
    "df['ec_num'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enzyme types distribution\n",
    "df['enzyme_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d545454",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_val_data = get_external_validation_pdb_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take out external validation data\n",
    "df_external_val = df[df['uniprot_id'].isin(uniprot_val_data)].reset_index(drop=True)\n",
    "df = df[df['uniprot_id'].isin(uniprot_val_data)==False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec903e",
   "metadata": {},
   "source": [
    "### Data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa250c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c78a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_feat_var = define_features_var_grouping(df)\n",
    "feat_cols = grouped_feat_var['feat_cols']\n",
    "feat_cols_dim0 = grouped_feat_var['feat_cols_dim0']\n",
    "feat_cols_begin_end = grouped_feat_var['feat_cols_begin_end']\n",
    "features_var_dict_dim_land_shape_extrema = grouped_feat_var['features_var_dict_dim_land_shape_extrema']\n",
    "features_var_dict_dim_land = grouped_feat_var['features_var_dict_dim_land']\n",
    "features_var_dict_dim = grouped_feat_var['features_var_dict_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation among group of features\n",
    "for key in features_var_dict_dim_land.keys():\n",
    "    df_corr = df[np.sort(features_var_dict_dim_land[key])].corr('spearman')\n",
    "    sns.heatmap(df_corr, annot = True, fmt = '.2f')\n",
    "    print(key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considerations:\n",
    "# - dim 0 features are very correlated, what about taking only 0, 2 and 4?\n",
    "# - begin_dim1 and end_dim1 are correlated, while Fourier coefficients are not (makes sense)\n",
    "# - a10 is bigger than b10 for first landscape since for the approximated function we have f(0)=0 like sin, \n",
    "# - what if we take fewer Fourier coefficients? 3-series instead of 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18690c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation with outcome\n",
    "y = df['enzyme_type'].apply(lambda x: enzyme_ec_label_dict[x]).values\n",
    "corrs = []\n",
    "for var in feat_cols:\n",
    "    corrs += [spearmanr(df[var],y)[0]]\n",
    "df_corr_outcome = pd.DataFrame(zip(feat_cols,corrs),columns=['feat','corr']).sort_values(by='corr',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab7847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_corr_outcome.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94379b",
   "metadata": {},
   "source": [
    "#### Train-test split and outliers removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=test_size, stratify=df['enzyme_type'], random_state=seed)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train[feat_cols]\n",
    "x_test = df_test[feat_cols]\n",
    "y_train = df_train['enzyme_type'].apply(lambda x: enzyme_ec_label_dict[x]).values\n",
    "y_test = df_test['enzyme_type'].apply(lambda x: enzyme_ec_label_dict[x]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e7aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers in the training dataset based on begin and end of 0,1,and 2 dim features (this should hint errors in recorded coordinates and the resulting distributions looks nicer than if we remove only dim0 features)\n",
    "# contamination gives the proportion of outliers we wish to remove, default is \"auto\"\n",
    "iso_forest = IsolationForest(contamination=0.1) # contamination was set so that the feature distribution histograms are close to normal\n",
    "yhat = iso_forest.fit_predict(x_train[feat_cols_begin_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "print(\"num original samples:\", len(x_train))\n",
    "print(\"num samples after removing outliers:\", sum(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "x_train_no_out, y_train_no_out = x_train[mask], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3880423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check features distribution\n",
    "for key in features_var_dict_dim_land.keys():\n",
    "    x_train[features_var_dict_dim_land[key]].hist(figsize=(10,10))\n",
    "    print(key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8480965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check features distribution after removing outliers\n",
    "for key in features_var_dict_dim_land.keys():\n",
    "    x_train_no_out[features_var_dict_dim_land[key]].hist(figsize=(10,10))\n",
    "    print(key)\n",
    "    plt.show()\n",
    "# Now features distribution makes more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevalence with and without outlier is similar\n",
    "df_enz_type_prev = df['enzyme_type'].value_counts()/len(df['enzyme_type']) * 100\n",
    "df_enz_type_prev_no_out = pd.DataFrame(y_train_no_out).value_counts()/len(y_train_no_out) * 100\n",
    "print(df_enz_type_prev)\n",
    "print(df_enz_type_prev_no_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look how extreme outliers look like\n",
    "iso_forest_extreme_outlier= IsolationForest(contamination=0.0001)\n",
    "yhat_extreme_outlier = iso_forest_extreme_outlier.fit_predict(x_train[feat_cols_dim0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16505e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extreme_out = df_train[yhat_extreme_outlier==-1]\n",
    "# todo: check 3d plot of outliers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many proteins have trivial global shapes so we can't conclude much from persistence homology.\n",
    "# Let's look for proteins having one single connected component and non-trivial homology in dim 1 and 2.\n",
    "# Anyway keep in mind all knots in 3d are homotopy equivalent, so we should not be able to tell the difference between different knotted chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_out = df.loc[x_train_no_out.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3a6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fun_homology = interesting_homology_filter(df_tfda_enc=df_no_out, feat_var_dict_dim_land=features_var_dict_dim_land)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fun_homology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f7c16",
   "metadata": {},
   "source": [
    "#### Pairwise distance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578f4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to smaller dataset to allow faster computation of pairwise distances\n",
    "df_small = df.loc[df_fun_homology.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pairwise distance at different aggregation levels\n",
    "pair_dist_dict = pairwise_dist(df=df_small, dict_features_var_dims_lands=features_var_dict_dim_land_shape_extrema)\n",
    "pair_dist_dict_dim = aggregate_metrics_dim(pair_dist_dict)\n",
    "pair_dist_final = aggregate_metrics_all(pair_dist_dict_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b706738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dim0_close_pairs = get_samples_low_high_pos_dist(pair_dist_dict_dim['dim0'], n=5, low=True).drop_duplicates().rename(columns={'distance':'distance0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb782ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dim1_close_pairs = get_samples_low_high_pos_dist(pair_dist_dict_dim['dim1'], n=5, low=True).drop_duplicates().rename(columns={'distance':'distance1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e596db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dim2_close_pairs = get_samples_low_high_pos_dist(pair_dist_dict_dim['dim2'], n=5, low=True).drop_duplicates().rename(columns={'distance':'distance2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff3b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dim1_close_dim2_close = df_dim1_close_pairs.merge(df_dim2_close_pairs).sort_values(by='distance1',ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b736a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dim1_close_dim2_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d60aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fun_homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = get_similar_protein_pairs(df_fun_homology, pair_dist_final, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab03303",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.sort_values(by=['area_dim1_land3_pdb1','pdb_id1','distance'],ascending=[False,False,True])#.head(20)\n",
    "# nice example:7CW2, 7CW3, 7CVZ, 6Z6O, 3J0F, 3J0C are similar viruses - Chikungunya,  Sindbis virion and Venezuelan Equine Encephalitis Virus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ebe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33077c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_protein_pairs(pair_dist_dict_dim['dim1'], n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3291e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2728"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a73e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2727,2730):\n",
    "    sim_pair = list(df_similar_dist_diff_type.reset_index(drop=True)[['pdb_id1','pdb_id2']].loc[i].values)\n",
    "    compare_pdb_pairwise_dist(pdb_id1=sim_pair[0], pdb_id2=sim_pair[1], dict_dist_no_aggr=pair_dist_dict, dict_dist_aggr_dim=pair_dist_dict_dim, dist_aggr_global=pair_dist_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34688767",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair = list(df_similar_dist_diff_type.reset_index(drop=True)[['pdb_id1','pdb_id2']].loc[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "j=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair = list(df_dim0_close_dim1_far[['pdb_id1','pdb_id2']].loc[j].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pair = ['4YMK','4EKZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9856973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4TOB (big dim2 hole) and 2P0I (small dim2 hole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pdb_pairwise_dist(pdb_id1=sim_pair[0], pdb_id2=sim_pair[1], dict_dist_no_aggr=pair_dist_dict, dict_dist_aggr_dim=pair_dist_dict_dim, dist_aggr_global=pair_dist_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe1b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d plots from pdb website are nicer and also seem a bit different..is it or is it just a matter of perspective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice examples: 4A9G (sphere), 7CM5 (torus), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8661293",
   "metadata": {},
   "source": [
    "#### Data visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424cee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_pdb_plots(pdb_list=sim_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbe656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for examples with high dim1/2 difference and low dim0 diff\n",
    "# what's persistence homology of a 3d knot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df9f1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Multi Dimensional Scaling on pairwise distances to visualize data in 3d\n",
    "# This is done at different aggregation levels\n",
    "# No aggregation\n",
    "for k, v in zip(pair_dist_dict.keys(), pair_dist_dict.values()):\n",
    "    apply_mds(title=k,df_dissim=v,labels=df_small['enzyme_type'],enzyme_color_dict=enzyme_ec_label_color_dict)\n",
    "# Aggregate at dim level\n",
    "for k, v in zip(pair_dist_dict_dim.keys(), pair_dist_dict_dim.values()):\n",
    "    apply_mds(title=k,df_dissim=v,labels=df_small['enzyme_type'],enzyme_color_dict=enzyme_ec_label_color_dict)\n",
    "# Aggregate all dims and all lands\n",
    "apply_mds(title='all dim',df_dissim= pair_dist_final,labels=df_small['enzyme_type'],enzyme_color_dict=enzyme_ec_label_color_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641ba674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: reduce size of created pngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6893e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems hydrolases can have multiple 3dim holes while other enzymes usually do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d919c7c0",
   "metadata": {},
   "source": [
    "#### Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44398fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection? are all the 3 landscapes and 5 fourier coefficients useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e47d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_pos_weight = y_text.value_counts()[0]/y_text.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats import loguniform\n",
    "#loguniform(1e-6, 1e-3).rvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed449a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare cv parameters\n",
    "cv_params = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'gamma': np.linspace(0,0.5,5),\n",
    "    'max_depth': [10, 15, 25],\n",
    "    'min_child_weight': [1,2,5],\n",
    "    'subsample':np.linspace(0.5,1,5),\n",
    "    'n_estimators':[100, 200, 500, 1000],\n",
    "        }    \n",
    "\n",
    "# add scale_pos weight\n",
    "# eta is same as learning_rate\n",
    "# \"objective\":\"binary:logistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34191066",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = xgboost.XGBClassifier()\n",
    "xgb_classifier_cv = RandomizedSearchCV(xgb_classifier,param_distributions=cv_params,n_iter=100,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e3f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CV (takes some time) and store best parameters as json\n",
    "# xgb_classifier_cv.fit(x_train, y_train)\n",
    "# best_classifier = xgb_classifier_cv.best_estimator_\n",
    "# best_classifier_params = xgb_classifier_cv.best_estimator_.get_params()\n",
    "#with open(\"output/xgboost_cv_best_params.json\", \"w\") as f:\n",
    "#    json.dump(best_params , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b94316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_xgboost_params_cv_path = \"output/xgboost_cv_best_params.json\"\n",
    "#best_xgboost_params_cv = json.load(open(best_xgboost_params_cv_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ceff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = xgboost.XGBClassifier(**best_xgboost_params_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339614b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best.fit(x_train_no_out,y_train_no_out -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0dbb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = xgb_best.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b9684",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = xgb_best.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd51366",
   "metadata": {},
   "outputs": [],
   "source": [
    "enzyme_ec_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3260da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['enzyme_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914109b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "confusion_matrix(y_true=y_test-1,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f137cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test-1,y_score=y_pred_proba, average='weighted', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true=y_test-1,y_pred=y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75255868",
   "metadata": {},
   "outputs": [],
   "source": [
    "matthews_corrcoef(y_true=y_test-1,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - five 0-dim bars\n",
    "# - begin/end domain of land 1, followed by 1 + 5*2 fourier coeff a0,a1,b1,a2,b2,... repeated num_1dim_landscapes time\n",
    "# - begin/end domain of land 2, followed by 1 + 5*2 fourier coeff a0,a1,b1,a2,b2,... repeated num_2dim_landscapes time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_importance(xgb_best,max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b94607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_imp = pd.DataFrame(xgb_best.feature_importances_, columns=['feat_imp'], index=x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fffc52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_feat = 10\n",
    "num_bottom_feat = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d551de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_feat = df_feat_imp.sort_values(by='feat_imp',ascending=False).head(num_top_feat)\n",
    "df_bottom_feat = df_feat_imp.sort_values(by='feat_imp',ascending=True).head(num_bottom_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(num_top_feat), df_top_feat['feat_imp'].values[::-1])\n",
    "y_pos = np.arange(num_top_feat)\n",
    "plt.yticks(y_pos, df_top_feat.index[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f43fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(num_top_feat), df_bottom_feat['feat_imp'].values[::-1])\n",
    "y_pos = np.arange(num_top_feat)\n",
    "plt.yticks(y_pos, df_bottom_feat.index[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b59d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data. linear models don't work well\n",
    "# model = LinearSVC(class_weight='balanced') - bad\n",
    "# model = LogisticRegression(class_weight='balanced') - bad\n",
    "# https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning\n",
    "# add cv together with max_depth increase\n",
    "# model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36351649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dmatrix = xgboost.DMatrix(data=x_train,label=y_train)\n",
    "#xgb_evaluation_cv = cv(dtrain=data_dmatrix, params=best_classifier_params, nfold=5, metrics=\"auc\", as_pandas=True, seed=123,num_boost_round=15)\n",
    "#xgb_evaluation_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77560df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for pairs of similar proteins. Are there any couples having similar shape but not similar sequence? some algorithms for protein clasification are based on sequence matching, is it enough? this could be better checked using bottleneck distance, but it would be more time consuming and be a different topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e15a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0638ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = pdist(x, metric='euclidean')\n",
    "dist_mat = squareform(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29965c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0[df0['pdb_id'] == '102L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef514a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0[df0['pdb_id'] == '4EW4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747caa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat_non_zero = dist_mat + np.identity(dist_mat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pairwise_dist_pdb_id1 = np.argmin(np.min(dist_mat_non_zero,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4094f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pairwise_dist_pdb_id2 = np.argmin(dist_mat_non_zero[min_pairwise_dist_pdb_id1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df0.loc[min_pairwise_dist_pdb_id1]['pdb_id'])\n",
    "print(df0.loc[min_pairwise_dist_pdb_id2]['pdb_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7fd404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dist_mat_non_zero).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b0791",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist_pdb_id1 = np.argmin(dist_mat_non_zero[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff84fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df0.loc[0]['pdb_id'])\n",
    "print(df0.loc[min_dist_pdb_id1]['pdb_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47606933",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat_non_zero[min_pairwise_dist_pdb_id1,min_pairwise_dist_pdb_id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee9369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 distance....are there duplicates??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ae125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no surprise they are similar, one is a mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# TSNE\n",
    "#tsne_result = TSNE(n_components=2, learning_rate='auto',init='random', perplexity=3).fit_transform(x_train_no_out)\n",
    "# Plot the result of our TSNE with the label color coded\n",
    "# A lot of the stuff here is about making the plot look pretty and not TSNE\n",
    "tsne_result_df = pd.DataFrame({'tsne_1': tsne_result[:,0], 'tsne_2': tsne_result[:,1], 'label': y_train_no_out})\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.scatterplot(x='tsne_1', y='tsne_2', hue='label', data=tsne_result_df, ax=ax,s=120)\n",
    "lim = (tsne_result.min()-5, tsne_result.max()+5)\n",
    "ax.set_xlim(lim)\n",
    "ax.set_ylim(lim)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3731ed74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x_train_no_out)\n",
    "# Apply PCA for data visualization\n",
    "# do not scale!\n",
    "pca = PCA(n_components = 2)\n",
    "data_pca = pca.fit_transform(x_train_no_out)\n",
    "data_pca = pd.DataFrame(data_pca,columns=['PC1','PC2'])\n",
    "data_pca['enzyme_type'] = y_train_no_out\n",
    "sns.scatterplot(data=data_pca, x=\"PC1\", y=\"PC2\", hue=\"enzyme_type\",alpha=0.7)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tda_env_kernel",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
